# 理解大模型

open-api 文档

官方 https://openai.com/api/

中文 https://302ai.apifox.cn/api-147522039

## 输入

chat/completions

```bash
curl https://api.openai.com/v1/chat/completions
-H "Content-Type: application/json"
-d '{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "你是一个友好的个人助理，可以回答我生活相关的问题"
    },
    {
      "role": "user",
      "content": "提问：法国的首都在哪？"
    },
    {
      "role": "assistant",
      "content": "今天天气很暖和"
    },
    {
      "role": "user",
      "content": "我应该带伞么？"
    }
  ]
}'
```

通过 role 和 content 对象数组记录对话历史

role 主要有四种 System，User，Assistant，Tool

### token

文本转换成模型可理解的符号

文本 -> token -> token IDs

oken 不等于字符或单词，不同语言 token 表达效率不同

不同模型使用的分词器不同

### token 补全

模型通过预测下一个 token 来生成

例如："我喜欢吃" → 预测下一个 token
可能的 token 及其概率：

"饭" (0.3)
"菜" (0.2)
"水果" (0.15)
"零食" (0.1)
...其他选项

有很多参数影响补全效果

- Temperature：低温强化高概率选项，减少选择多样性
  ，高温使概率分布更平缓，增加选择多样性

- Top_p 核采样：设定累积概率阈值，从高到低概率依次选择的 token，直到总和达到设定值

- Frequency Penalty 概率惩罚：降低已出现 token 的再次出现概率，迫使模型选择新的表达方式

- Presence Penalty 存在惩罚：降低已出现主题的相关 token 概率，促使模型转向新主题
